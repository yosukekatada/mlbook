{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "try:\n",
    "    xrange\n",
    "except NameError:\n",
    "    xrange = range\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ダミーデータを作ります</h2>\n",
    "\n",
    "ダミーデータは可視化しやすいように、2次元とします。そしてダミーデータを作る上に2次元正規分布からサンプリングしますが、そのための関数を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_2dim_normal(mean, variance, covariance, sample_size):\n",
    "    cov = [[variance, covariance],\n",
    "           [covariance, variance]]\n",
    "    return np.random.multivariate_normal(mean, cov, sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4つのクラスターを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster1 = generate_2dim_normal(mean=[0, 8], variance=1,\n",
    "                                covariance=0, sample_size=500)\n",
    "cluster2 = generate_2dim_normal(mean=[-1, 0], variance=1,\n",
    "                                covariance=0, sample_size=500)\n",
    "cluster3 = generate_2dim_normal(mean=[10, 10], variance=1,\n",
    "                                covariance=0, sample_size=300)\n",
    "cluster4 = generate_2dim_normal(mean=[5, 5.5], variance=0.8,\n",
    "                                covariance=-0.1, sample_size=200)\n",
    "data = np.vstack((cluster1, cluster2, cluster3, cluster4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それを可視化したのが以下です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(data[:, 0], data[:, 1])\n",
    "ax.set_title('scatter plot')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　Scikit-LearnのKMeans法を使ってクラスターを作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=4, init='k-means++', n_init=10, max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_labels = km.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#　グラフの描画の初期化\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "colorlist = ['tomato', 'antiquewhite', 'blueviolet', 'cornflowerblue',\n",
    "             'darkgreen', 'seashell', 'skyblue', 'mediumseagreen']\n",
    "\n",
    "#　クラスターの番号をユニークにします\n",
    "cluster_ids = list(set(cluster_labels))\n",
    "# cluster_idsは[0, 1, 2, 3]となっています\n",
    "\n",
    "#　クラスターごとに色を変えながら、散布図に出力していきます\n",
    "for k in range(len(cluster_ids)):\n",
    "    cluster_id = cluster_ids[k]\n",
    "    label_ = 'clutser = %d' % cluster_id\n",
    "    data_by_cluster = data[cluster_labels == cluster_id]\n",
    "    ax.scatter(data_by_cluster[:, 0], data_by_cluster[:, 1],\n",
    "               c=colorlist[k], label=label_)\n",
    "\n",
    "ax.set_title('Clustering')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>最適なクラスター数を探す: Elbow Method</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_cluster = 10\n",
    "clusters_ = range(1, max_cluster)\n",
    "intra_sum_of_square_list = []\n",
    "for k in clusters_:\n",
    "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300)\n",
    "    km.fit(data)\n",
    "    intra_sum_of_square_list.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_title('Elbow Method')\n",
    "ax.set_xlabel('Number of Clutser')\n",
    "ax.set_ylabel('Intra Sum of distances(WCSS)')\n",
    "plt.plot(clusters_, intra_sum_of_square_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>最適なクラスター数を探す: シルエットプロット</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "km = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10, max_iter=300)\n",
    "km.fit(data)\n",
    "cluster_labels = km.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(data, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "each_silhouette_score = silhouette_samples(data, cluster_labels,\n",
    "                                           metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "         each_silhouette_score[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = colorlist[i]\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0,\n",
    "                         ith_cluster_silhouette_values,\n",
    "                         facecolor=color, edgecolor=color, alpha=0.3)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax.set_title('Silhouette plot')\n",
    "ax.set_xlabel('Silhouette score')\n",
    "ax.set_ylabel('Cluster label')\n",
    "\n",
    "# The vertical line for average silhouette score of all the values\n",
    "ax.axvline(x=silhouette_avg, color='red', linestyle='--')\n",
    "\n",
    "ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "cluster_ids = list(set(cluster_labels))\n",
    "\n",
    "for k in range(len(cluster_ids)):\n",
    "    cluster_id = cluster_ids[k]\n",
    "    label_ = 'clutser = %d' % cluster_id\n",
    "    data_by_cluster = data[cluster_labels == cluster_id]\n",
    "    ax.scatter(data_by_cluster[:, 0], data_by_cluster[:, 1],\n",
    "               c=colorlist[k], label=label_)\n",
    "\n",
    "ax.set_title('Clustering')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>実際のデータを使ってやってみましょう</h2>\n",
    "\n",
    "本日使用するデータはこちらから入手しました。\n",
    "http://archive.ics.uci.edu/ml/datasets/Wholesale+customers#\n",
    "\n",
    "datasetフォルダのWholesale_customers_data.csvを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wholsesale_data = pd.read_csv('dataset/Wholesale_customers_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のウェブページから抜粋したのが以下です。ポルトガルの卸売業者のカテゴリ別のSpending仕入量？のデータです。このデータを使って、卸売業者をセグメンテーションしてみましょう。\n",
    "\n",
    "Abstract: The data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories\n",
    "\n",
    "*\tFRESH: annual spending (m.u.) on fresh products (Continuous); \n",
    "*\tMILK: annual spending (m.u.) on milk products (Continuous); \n",
    "*\tGROCERY: annual spending (m.u.)on grocery products (Continuous); \n",
    "*\tFROZEN: annual spending (m.u.)on frozen products (Continuous) \n",
    "*\tDETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) \n",
    "*\tDELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); \n",
    "*\tCHANNEL: customersâ€™ Channel - Horeca (Hotel/Restaurant/CafÃ©) or Retail channel (Nominal) \n",
    "*\tREGION: customersâ€™ Region â€“ Lisnon, Oporto or Other (Nominal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wholsesale_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、気になるのはChannelとReginがカテゴリ変数だということです。KMeans法は連続値を想定しているということです。そのため、ChannelとReginは外しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper',\n",
    "        'Delicassen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_for_cl = wholsesale_data[cols]\n",
    "dataset_for_cl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "忘れてはいけないのが前処理。ユークリッド距離に基づいてクラスタリングするので、スケールは重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "scaler = MaxAbsScaler()\n",
    "dataset_for_cl_scaled = scaler.fit_transform(dataset_for_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow Methodを使って最適なクラスター数を探してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_cluster = 10\n",
    "clusters_ = range(1, max_cluster)\n",
    "intra_sum_of_square_list = []\n",
    "for k in clusters_:\n",
    "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300)\n",
    "    km.fit(dataset_for_cl)\n",
    "    intra_sum_of_square_list.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_title('Elbow Method')\n",
    "ax.set_xlabel('Number of Clutser')\n",
    "ax.set_ylabel('Intra Sum of distances(WCSS)')\n",
    "plt.plot(clusters_, intra_sum_of_square_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シルエットプロットも見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_clusters = 6\n",
    "km = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10, max_iter=300)\n",
    "km.fit(dataset_for_cl_scaled)\n",
    "cluster_labels = km.predict(dataset_for_cl_scaled)\n",
    "\n",
    "silhouette_avg = silhouette_score(dataset_for_cl_scaled, cluster_labels)\n",
    "\n",
    "each_silhouette_score = silhouette_samples(dataset_for_cl_scaled,\n",
    "                                           cluster_labels, metric='euclidean')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "y_lower = 10\n",
    "\n",
    "for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = \\\n",
    "         each_silhouette_score[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = colorlist[i]\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0,\n",
    "                         ith_cluster_silhouette_values,\n",
    "                         facecolor=color, edgecolor=color, alpha=0.3)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax.set_title('Silhouette plot')\n",
    "ax.set_xlabel('Silhouette score')\n",
    "ax.set_ylabel('Cluster label')\n",
    "\n",
    "# The vertical line for average silhouette score of all the values\n",
    "ax.axvline(x=silhouette_avg, color='red', linestyle='--')\n",
    "\n",
    "ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に解釈してみましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km_centers = pd.DataFrame(km.cluster_centers_, columns=cols)\n",
    "km_centers.plot.bar(ylim=[0, 2], fontsize=10)\n",
    "km_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
